{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Steel Plates Fault Detection – Machine Learning Academic Report\n",
        "\n",
        "**This academic report covers Machine Learning work from **two full projects** completed in this course:**\n",
        "- `ml-project` – Cardiovascular Disease Prediction (Data Mining + Machine Learning)\n",
        "- `Steel_Fault_Project` – Steel Plates Fault Detection (Data Mining + Machine Learning + Optimization)\n",
        "\n",
        "**Institution:** Istanbul Nişantaşı University  \n",
        "**Course:** Machine Learning and Pattern Recognition (Makine Öğrenme ve Örüntü Tanıma)  \n",
        "**Instructor:** Dr. Öğr. Gülsüm Şanal  \n",
        "**Date:** December 2025\n",
        "\n",
        "---\n",
        "\n",
        "## Project Team\n",
        "\n",
        "Contributors (alphabetical order):\n",
        "\n",
        "- **Aigul Salimgareeva** (20251555001)\n",
        "- **Nima Taghipour Chokami** (20241555012)\n",
        "- **Rayan Aksu** (20251556003)\n",
        "\n",
        "*All team members contributed equally to this project.*\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Projects Overview\n",
        "\n",
        "During the semester, we worked on **two complete projects** that share a similar Machine Learning pipeline:\n",
        "\n",
        "1. **Steel Plates Fault Detection – Machine Learning Project** (`Project_2_MachineLearning` in `Steel_Fault_Project_v2`)\n",
        "2. **Cardiovascular Disease Prediction – Machine Learning Part** of the original **ml-project**\n",
        "\n",
        "In both projects, we start from a **processed and feature-engineered dataset** (output of the Data Mining phase) and then:\n",
        "\n",
        "- Split data into train/test sets\n",
        "- Scale features where necessary\n",
        "- Train multiple classification algorithms\n",
        "- Evaluate and compare models using standard metrics\n",
        "- Perform hyperparameter optimization\n",
        "- Save the best models for later use\n",
        "\n",
        "In the following sections, we first describe the **Steel Fault Detection** Machine Learning project (Section 2), and then we summarize the **Cardiovascular Disease** Machine Learning work from the ml-project (Section 4).\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Steel Fault Detection – Machine Learning (Current Project)\n",
        "\n",
        "### 2.1 Data Pipeline\n",
        "\n",
        "The Machine Learning project for steel plates uses the engineered dataset produced by the Data Mining project:\n",
        "\n",
        "- Input file: `Project_2_MachineLearning/data/processed/steel_plates_engineered.csv`\n",
        "- Source: `03_feature_engineering_EN/TR` in `Project_1_DataMining`\n",
        "- Features: 27 original + 23 engineered ≈ 50 total\n",
        "- Target: fault class (multi-class classification)\n",
        "\n",
        "The data pipeline can be summarized as:\n",
        "\n",
        "```\n",
        "Project_1_DataMining           →   Project_2_MachineLearning\n",
        "01_data_exploration            →   01_model_training\n",
        "02_data_preprocessing          →   02_model_evaluation\n",
        "03_feature_engineering (50 features)\n",
        "          ↓\n",
        "steel_plates_engineered.csv → models and metrics\n",
        "```\n",
        "\n",
        "### 2.2 Model Training (01_model_training)\n",
        "\n",
        "In `01_model_training_EN/TR`, we trained and compared **8 classification models** on the engineered steel dataset:\n",
        "\n",
        "1. **Logistic Regression** – Linear baseline model\n",
        "2. **Decision Tree** – Rule-based, interpretable model\n",
        "3. **Random Forest** – Ensemble of decision trees\n",
        "4. **K-Nearest Neighbors (KNN)** – Instance-based model\n",
        "5. **Support Vector Machine (SVM)** – Margin-based classifier\n",
        "6. **Naive Bayes** – Probabilistic classifier\n",
        "7. **Neural Network (MLPClassifier)** – Multi-layer perceptron\n",
        "8. **Gradient Boosting** – Boosted trees\n",
        "\n",
        "**Workflow:**\n",
        "\n",
        "- Load `steel_plates_engineered.csv`\n",
        "- Separate features `X` and target `y`\n",
        "- Create **train/test split** with stratification to preserve class distribution\n",
        "- Apply `StandardScaler` for algorithms sensitive to scale (LR, KNN, SVM, NN)\n",
        "- Train each model with reasonable hyperparameters\n",
        "- Evaluate models using:\n",
        "  - Accuracy\n",
        "  - Precision, Recall, F1-Score\n",
        "  - Cross-validation where appropriate\n",
        "- Collect all results into a comparison table (`model_comparison_results.csv`)\n",
        "\n",
        "**Model saving:**\n",
        "\n",
        "At the end of training, we created a `models/` directory and saved:\n",
        "\n",
        "- `*_model.pkl` – all trained models\n",
        "- `scaler.pkl` – fitted `StandardScaler`\n",
        "- `label_encoder.pkl` – encoder for class labels\n",
        "- `model_comparison_results.csv` – metrics for all models\n",
        "- `best_model.pkl` – best-performing model selected by our chosen metric\n",
        "\n",
        "This makes the ML project **reproducible and deployable**.\n",
        "\n",
        "### 2.3 Model Evaluation (02_model_evaluation)\n",
        "\n",
        "In `02_model_evaluation_EN/TR`, we performed **deeper analysis** of selected models (especially the best ones, such as Random Forest):\n",
        "\n",
        "- Generated confusion matrices\n",
        "- Calculated per-class precision, recall, and F1-scores\n",
        "- Investigated which classes are harder to predict\n",
        "- Visualized results using plots in the `figures/` directory\n",
        "\n",
        "This evaluation step connects the raw metrics (Accuracy, F1, etc.) to **practical interpretation** for fault detection: which defect types are often confused, and where the model performs best or worst.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Steel Fault Optimization – Model Optimization Project\n",
        "\n",
        "The optimization phase is implemented as a **separate project**: `Project_3_Optimization`.\n",
        "\n",
        "### 3.1 Goal\n",
        "\n",
        "Compare different hyperparameter optimization methods for Random Forest on the engineered steel dataset:\n",
        "\n",
        "- **Grid Search** – Exhaustive search over a predefined parameter grid\n",
        "- **Random Search** – Random sampling from parameter distributions\n",
        "\n",
        "### 3.2 Workflow (01_model_optimization)\n",
        "\n",
        "- Load `Project_3_Optimization/data/processed/steel_plates_engineered.csv`\n",
        "- Split into train/test with stratification\n",
        "- Apply `StandardScaler` where necessary\n",
        "- Define parameter spaces:\n",
        "  - For Grid Search: explicit lists of values (e.g., `n_estimators`, `max_depth`, `min_samples_split`)\n",
        "  - For Random Search: distributions over ranges (e.g., `randint` for `n_estimators`)\n",
        "- Run 5-fold cross-validation for each optimization method\n",
        "- Measure:\n",
        "  - Best cross-validation score\n",
        "  - Test score on hold-out set\n",
        "  - Total computation time\n",
        "- Visualize search results (e.g., scatter plots of mean CV score vs. configuration index)\n",
        "\n",
        "### 3.3 Saving Optimized Models\n",
        "\n",
        "At the end of optimization, we saved:\n",
        "\n",
        "- `random_forest_optimized_grid.pkl` – best model from Grid Search\n",
        "- `random_forest_optimized_random.pkl` – best model from Random Search\n",
        "- `best_optimized_model.pkl` – best overall optimized model\n",
        "- `optimized_model_comparison.csv` – comparison of methods and scores\n",
        "\n",
        "This project is conceptually similar to **Phase 3: Hyperparameter Tuning** in the ml-project, but here it is isolated as a dedicated **Optimization** project.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Cardiovascular Disease – Machine Learning (ml-project)\n",
        "\n",
        "In the original **ml-project**, the Machine Learning part used a **cardiovascular disease dataset** (70,000 records). After Data Mining (EDA, preprocessing, and feature engineering), we trained and compared several models.\n",
        "\n",
        "### 4.1 Data Preparation\n",
        "\n",
        "- Input: `cardio_engineered.csv` (cleaned and feature-engineered dataset)\n",
        "- Train/test split:\n",
        "  - 80% train, 20% test\n",
        "  - Stratified by target (disease vs no disease)\n",
        "- `StandardScaler` applied to continuous features for distance- and margin-based models\n",
        "\n",
        "### 4.2 Models Trained\n",
        "\n",
        "We trained 6 classification algorithms:\n",
        "\n",
        "1. Logistic Regression\n",
        "2. Decision Tree\n",
        "3. Random Forest\n",
        "4. K-Nearest Neighbors (KNN)\n",
        "5. Support Vector Machine (SVM)\n",
        "6. Naive Bayes\n",
        "\n",
        "We evaluated each model using:\n",
        "\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1-Score\n",
        "- ROC-AUC\n",
        "\n",
        "The **best model** was **Random Forest**, achieving approximately:\n",
        "\n",
        "- Accuracy ≈ 73.76%\n",
        "- ROC-AUC ≈ 0.80\n",
        "\n",
        "### 4.3 Optimization and Cross-Validation\n",
        "\n",
        "In the ml-project academic report, we also performed:\n",
        "\n",
        "- **Grid Search** for Random Forest and Logistic Regression\n",
        "- Partial (resource-limited) Grid Search for SVM\n",
        "- 5-fold cross-validation to estimate model stability\n",
        "- Feature importance analysis for Random Forest\n",
        "\n",
        "These steps correspond to what we later implemented as a separate **Optimization** project for steel.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Comparison and Key Takeaways (Machine Learning)\n",
        "\n",
        "Despite using different datasets and domains (industrial vs medical), the Machine Learning workflow is very similar in both projects.\n",
        "\n",
        "### 5.1 Similarities\n",
        "\n",
        "- **Multiple algorithms** evaluated (LR, DT, RF, KNN, SVM, NB; plus NN and Gradient Boosting for steel)\n",
        "- **Train/test split** with stratification\n",
        "- **Scaling** with `StandardScaler` where appropriate\n",
        "- Use of **standard metrics** (Accuracy, Precision, Recall, F1, ROC-AUC)\n",
        "- **Random Forest** and other tree-based ensembles performed best overall\n",
        "- **Optimization** using Grid Search / Random Search and cross-validation\n",
        "\n",
        "### 5.2 Differences\n",
        "\n",
        "- **Domain:**\n",
        "  - Steel project: industrial **fault type** prediction (multi-class)\n",
        "  - Cardio project: medical **disease presence** prediction (binary)\n",
        "\n",
        "- **Feature types:**\n",
        "  - Steel: mainly **geometric** and **intensity** features engineered from images\n",
        "  - Cardio: **clinical** and **lifestyle** features, plus engineered medical indicators (BMI, MAP, etc.)\n",
        "\n",
        "- **Project structure:**\n",
        "  - ml-project: Data Mining, ML, and Optimization all in one project (with phases in a single academic report)\n",
        "  - Steel_Fault_Project_v2: three separate but connected projects: Data Mining, Machine Learning, Optimization\n",
        "\n",
        "### 5.3 Lessons Learned\n",
        "\n",
        "From the Machine Learning perspective, we learned that:\n",
        "\n",
        "- Good **data preparation and feature engineering** (from the Data Mining project) are crucial for strong ML performance\n",
        "- **Tree-based ensemble methods** (especially Random Forest) are robust baselines for both industrial and medical classification problems\n",
        "- **Hyperparameter optimization** (Grid Search, Random Search) provides consistent but sometimes modest improvements over well-chosen default settings\n",
        "- **Cross-validation** is essential for reliable performance estimates and model selection\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Course Learning Outcomes (Machine Learning)\n",
        "\n",
        "Through these projects, we achieved the following learning outcomes for the **Machine Learning and Pattern Recognition** course:\n",
        "\n",
        "- Implementing and comparing multiple classification algorithms on real datasets\n",
        "- Applying proper **train/test splitting** and **scaling** strategies\n",
        "- Using a wide range of **evaluation metrics** (Accuracy, Precision, Recall, F1, ROC-AUC)\n",
        "- Performing **hyperparameter tuning** with `GridSearchCV` and `RandomizedSearchCV`\n",
        "- Understanding **bias-variance trade-offs** across models\n",
        "- Saving trained models and building **reproducible ML pipelines**\n",
        "\n",
        "Together with the Data Mining work, this Machine Learning project for steel faults mirrors the structure and rigor of the original **ml-project**, but in an industrial setting instead of healthcare.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executive Summary\n",
        "\n",
        "This academic report summarizes the **Machine Learning** work from **two full projects**:\n",
        "\n",
        "1. **Steel Plates Fault Detection – Machine Learning Project** (`Steel_Fault_Project` / `Project_2_MachineLearning`)\n",
        "2. **Cardiovascular Disease Prediction – Machine Learning Part** of the original `ml-project`\n",
        "\n",
        "In the **Steel Fault** project, we used the engineered dataset (`steel_plates_engineered.csv`, ~50 features) produced by Data Mining and trained **8 classification models** (Logistic Regression, Decision Tree, Random Forest, K‑Nearest Neighbors, Support Vector Machine, Naive Bayes, Neural Network, Gradient Boosting). We performed stratified train/test splitting, feature scaling where needed, compared models using Accuracy, Precision, Recall, and F1, and saved all trained models plus the best model and scaler for later use. A separate Optimization project then applied Grid Search and Random Search to further tune Random Forest.\n",
        "\n",
        "In the **Cardiovascular** ml-project, we used the cleaned and engineered medical dataset (`cardio_engineered.csv`) to train multiple algorithms (Logistic Regression, Decision Tree, Random Forest, KNN, SVM, Naive Bayes), evaluated them with Accuracy, F1, and ROC‑AUC, and applied Grid Search hyperparameter tuning (especially for Random Forest and Logistic Regression). The best model (Random Forest) achieved around **73–74% accuracy** with ROC‑AUC ≈ 0.80.\n",
        "\n",
        "These two Machine Learning projects show that the same pipeline—**train/test split, scaling, multi‑model comparison, hyperparameter optimization, and model saving**—can be applied successfully to both an **industrial** fault detection problem and a **medical** disease prediction problem.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
